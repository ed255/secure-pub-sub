\section{Evaluation}
\label{sec:evaluation}

% TODO: Setting.  Computer resources (CPU, RAM, OS).

\subsection{Setup}

We have evaluated our implementation in an environment consisting on two
computers located in the same gigabit ethernet network.  We run the Broker,
Third Party and one Subscriber on the first computer, and all the Publishers in
the second computer.  We perform all the analysis on the performance of several
operations in the Broker and Third Party, which run together in a computer
running Linux with an Intel Core i7-6600U CPU with 16GB of RAM.  In order to
avoid isolate the performance influence of the Broker and the Third Party, we
have serialized the garbling and evaluation of the garbled circuit operations,
mimicking the situation in which the Broker and Third Party are run on
different servers.

\subsection{Microbenchmarks}

We have selected 5 numerical operations of varying complexity (\emph{summation,
multiplicatory, mean, variance, minimum}) to evaluate the cost of the different
parts of our implementation.  We securely evaluate these functions over the
values (encoded as 32 bit fixed point numbers) received from a variable number
of Publishers.

% TODO: Indicate the number of experiments per value

% Plots
\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{plots/garble.png}
        \caption{Garble}
        \label{fig:micro-garble-time}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{plots/eval.png}
        \caption{Evaluate}
        \label{fig:micro-eval-time}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{plots/send.png}
        \caption{Send}
        \label{fig:micro-send-time}
    \end{subfigure}
    \caption{Mean time required for garbling, evaluating and sending the
    garbled circuit to the Broker for each function in the microbenchmark, with
    a 95\% confidence intervals of the samples obtained in the evaluation shown
    in gray.  Sending includes the marshaling and unmarshaling of the garbled
    circuit and associated data structures.}\label{fig:micro-times}
\end{figure*}


\begin{figure}
  \includegraphics[width=0.45\textwidth]{plots/nonxor_gates_log.png}
  \caption{Non-XOR gates count per function used in the microbenchmarks.}
  \label{micro-nonxor}
\end{figure}

\begin{figure}
  \includegraphics[width=0.45\textwidth]{plots/enc_dec_inputs.png}
  \caption{Time spent garbling and evaluating the identity input gates.}
  \label{micro-inputs}
\end{figure}

%\begin{figure}
%  \includegraphics[width=0.45\textwidth]{plots/sum_circuit_2017-05-15.png}
%  \caption{Time spent garbling the circuit, sending the result to the Broker and evaluating it.}
%\end{figure}

%\begin{figure}
%  \includegraphics[width=0.45\textwidth]{plots/sum_circuit_onepub_2017-05-13.png}
%  \caption{Time spent garbling the circuit, sending the result to the Broker
%  and evaluating it removing the overhead of handling the Publishers
%  connections.}
%\end{figure}

\begin{figure}
  \includegraphics[width=0.45\textwidth]{plots/size_log.png}
  \caption{Size of the garbled circuit and the associated date required by the
  Broker to evaluate it.}
  \label{micro-sizes}
\end{figure}

We can see that the time spent encrypting and decrypting the inputs (that is,
garbling and evaluating the input identity gates) makes a significant influence
in the mean, min/max and sum microbenchmark, being comparable in magnitude to
the evaluation and garbling time (notice that for sum, the input
encryption/decryption time is even higher than the garbling/evaluation time).
We attribute this behavior to the fact that this part of the protocol is
implemented in go instead of C like the garbling and evaluation.

\subsection{Applications}

% TODO: 1. Turonet, wireless propagation constant, linear regression
\paragraph{Linear regression}

% One dimensional linear regression

% Questions: How many data points to use?

% Formula:
In this application we are interested in learning the linear model of two data
streams generated by Publishers.  In particular, we perform a linear regression
so that we can model one variable (comming from one stream) as a linear
combination of another variable (comming from another stream): $y = ax + b$.
To estimate the parameters of the one dimensional linear model we use the
ordinary least squares technique, which gives us the following closed-form
formula:

$\begin{pmatrix} b \\ c \end{pmatrix} =
\left( \displaystyle\sum_{i=1}^n \begin{pmatrix} 1 \\ x_i \end{pmatrix}
  \begin{pmatrix} 1 & x_i\end{pmatrix}\right)^{-1}
\left( \displaystyle\sum_{i=1}^n y_i \begin{pmatrix} 1 \\ x_i \end{pmatrix}\right)$

Evaluating the formula requires an inversion of a $2 x 2$ matrix, which we perform
by following the analytic solution.

% TODO: 2. Environmental Berkeley indor sensing data, correlation
\paragraph{Correlation}

% The dataset provides 2.3 million readings collected from sensors with the
% following values: temperature (degree Celcius), humidity (0-100%), light
% (Lux: 0-100000), identified by sensor ID.

% Ideas: correlation temperature~humidity, temperature~light.
% Questions: How many data points to use?
% Graph: varying number of points, do sampling

% We assume each sensor is an individual publisher.  The Broker accumulates
% streams of values from each sensor.  When requested, the Broker samples pairs
% of those streams at random to perform a correlation analysis between the two.

% Formula:

$r_{xy} = \frac{\displaystyle\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}
{\sqrt{\displaystyle\sum_{i=1}^n (x_i - \bar{x})^n (y_i - \bar{y})^n}}$

To improve efficiency, we evaluate the squared correlation ($r_{xy}^2$) to avoid
computing the square root in the function circuit, which would be an expensive
operation.

\begin{figure}
  \includegraphics[width=0.45\textwidth]{plots/stream.png}
  \caption{Mean time required for garbling, evaluating and sending the garbled
  circuit to the Broker for computing the correlation and linear regression of
  data streams, with a 95\% confidence intervals of the samples obtained in the
  evaluation shown in gray.  Sending includes the marshaling and unmarshaling
  of the garbled circuit and associated data structures.  Garbling and
  evaluating includes the time to garble and evaluate the input identity.}
  \label{stream-times}
\end{figure}

% TODO: 3. LAX parking lot dataset, statistics
\paragraph{Continuous statistics of incoming data}

% https://data.lacity.org/dataset/Los-Angeles-International-Airport-LAX-Parking-Lots/dik5-hwp6
% The dataset provides at a frequency of every 5 minutes and for every one of
% the 9 parking lots: total, occupied and free parking spaces.
% That's 288 values per day per parking lot.

% Privacy: Avoid revealing parking lot data at fine granularity, only reveal
% statistics of the data accumulated throughout the day.  Don't reveal data of
% individual parking lots, only combined data (except for the lot with
% more/less free spots)

Setting: We have 9 Publishers, one for each lot, which send data (current
number of free spots, current number of used spots) every 5 minutes.  The
Broker accumulates the data of a day and computes the statistics.  This
happens once per day.

% Daily statistics (used spots): mean, max, min, var of the number of cars in all the lots combined.
% Daily statistics (free spots): The marking lot which had more free spots, and the one
% that had less on average during the day.

% Time garble and time eval includes the time spend encrypting and decrypting
% the input values.

\begin{tabular}{l*{3}{r}r}
Statistic  & Garble & Send & Evaluate & Size \\
\hline
Mean       & 199.79 ms & 226.06  ms & 98.73  ms & 44.69 MB \\
Max/Min    & 163.28 ms & 172.38  ms & 84.93  ms & 31.97 MB \\
Variance   & 500.66 ms & 1055.63 ms & 236.08 ms & 222.08 MB \\
\hline
Most/Less free  & 121.27 ms & 85.04 ms & 67.55 ms & 16.65 MB \\
\end{tabular}

% "mean time_garble = 199.79 time_send = 226.06 time_eval = 98.73 size = 45768.73"
% "max  time_garble = 163.28 time_send = 172.38 time_eval = 84.93 size = 32744.84"
% "min  time_garble = 164.40 time_send = 165.77 time_eval = 84.14 size = 32744.84"
% "var  time_garble = 500.66 time_send = 1055.63 time_eval = 236.08 size = 227416.17"

% "max_free time_garble = 121.27 time_send = 85.04 time_eval = 67.55 size = 17059.81"
% "min_free time_garble = 120.98 time_send = 85.58 time_eval = 67.81 size = 17059.81"

% size =  44.69
% size =  31.97
% size =  31.97
% size = 222.08
% size =  16.65
% size =  16.65


% TODO: 4. Road Volume sensor traffic, evaluation of the expected time to follow a path
\paragraph{Estimation of time required to follow a path with traffic}

% http://rtmap.metro.net/ <- Not working (2017-05-15).

% TODO: 5. Smart bill, monthly electricity bill with different cost per hour of the day / threshold.

% ???

% TODO: Discussion: bottlenecks.

As expected, the time spent sending the garbled circuit from the Third Party to
the Broker is the most expensive part of the protocol, and thus is the current
bottleneck.  This means that the quality and bandwidth of the network
connection between the Broker and the Third Party is of critical importance.

The garbling and evaluation of the identity gates could be optimized by
incorporating the operations in the C code of libgarble.  Even though the
golang implementation of the AES encryption and decryption functions use the
Intel AES-NI hardware instructions, conversions from byte vectors to AES blocks
and vice versa slow down the operation.  On the other hand, libgarble works
natively with 128 byte data types (the size of an AES block) by using the Intel
SSE2 extensions, thus not requiring any conversion during
encryption/decryption.
